{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83deda8d-5336-424b-92fc-ccfba4f76570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df = pd.read_parquet(\"short_articles.parquet\")\n",
    "df = df[df[\"text\"].str.len() > 0].sample(frac=0.25)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac8be3-790b-4e49-b353-e57f5490d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect our ids for each article\n",
    "ids = df[\"article_id\"].tolist()\n",
    "## collect the properties that we will attach to each vector\n",
    "properties = df.apply(\n",
    "    lambda r:{ \n",
    "        \"url\": r.url, \n",
    "        \"title\": r.title, \n",
    "        \"title_len\": r.title_len, \n",
    "        \"text\": r.text, \n",
    "        \"text_len\": r.text_len}\n",
    "    , axis=1\n",
    ").tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6310ad9-902e-443d-ac1f-b8bc58abc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwak_inference import RealTimeClient\n",
    "\n",
    "data = [{\"input\": i} for i in df['text']]\n",
    "\n",
    "client = RealTimeClient(model_id=\"sentence_transformer\")\n",
    "\n",
    "vectors = []\n",
    "for i in range(0,len(data),250):\n",
    "    if i + 250 > len(data):\n",
    "        resp = client.predict(data[i:])\n",
    "    else:\n",
    "        resp = client.predict(data[i: i + 250])\n",
    "    vectors.extend([r['output'] for r in resp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f2225-075f-4e84-b36e-8960c35aec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwak.vector_store import VectorStoreClient\n",
    "\n",
    "client = VectorStoreClient()\n",
    "collection = client.get_collection_by_name(\"wikipedia-article-text-vectors\")\n",
    "\n",
    "collection.upsert(\n",
    "    ## List of the article ids\n",
    "    ids=ids,\n",
    "    ## List of vector values retrieved from the model prediction\n",
    "    vectors=vectors,\n",
    "    ## List of dict of the article properties\n",
    "    properties=properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fee2e1-be0a-4e8d-bd04-df3323fdef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwak.vector_store import VectorStoreClient\n",
    "from qwak_inference import RealTimeClient\n",
    "\n",
    "## Create inference client and use model to vectorize query\n",
    "inference_client = RealTimeClient(model_id=\"sentence_transformer\")\n",
    "vector = inference_client.predict([{\"input\": \"Ducks\"}])\n",
    "\n",
    "## Create vector client and fetch collection\n",
    "vector_client = VectorStoreClient()\n",
    "collection = vector_client.get_collection_by_name(\"wikipedia-demo\")\n",
    "\n",
    "## Search vector store using vector provided by model\n",
    "search_results = collection.search(\n",
    "    vector=vector[0]['output'], \n",
    "    top_results=3, \n",
    "    output_properties=[\"title\", \"title_len\", \"url\"], \n",
    "    include_distance=True, \n",
    "    include_vector=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7117b65-afed-449a-8d63-5736986d8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x.properties, x.distance) for x in search_results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
