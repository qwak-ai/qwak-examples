{
  "catboost": {
    "name": "Titanic Survival Prediction",
    "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/catboost.png",
    "source": {
      "folder": "titanic_conda/main",
      "files": [
        "__init__.py",
        "conda.yml",
        "model.py"
      ]
    },
    "deploy": {
      "pods": "1",
      "instance": "small"
    },
    "tags": [
      "Example model",
      "CatBoost"
    ]
  },
  "xgboost": {
    "name": "User Churn Estimation",
    "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/xg_boost.png",
    "source": {
      "folder": "xgboost_conda/main",
      "files": [
        "__init__.py",
        "conda.yml",
        "model.py"
      ]
    },
    "deploy": {
      "pods": "1",
      "instance": "small"
    },
    "tags": [
      "Example model",
      "XGBoost"
    ]
  },
  "llm": {
    "bert": {
      "name": "BERT base",
      "description": "Popular transformer-based model for uncased text processing",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/google.svg",
      "featured": true,
      "license": "Apache 2.0",
      "source": {
        "folder": "bert_conda/main",
        "files": [
          "__init__.py",
          "conda.yml",
          "model.py"
        ]
      },
      "deploy": {
        "pods": "1",
        "instance": "small"
      },
      "tags": [
        "LLM"
      ]
    },
    "distilgpt2": {
      "name": "DistilGPT2",
      "description": "A lightweight version of the GPT-2 language generation model",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/huggingface.png",
      "featured": true,
      "license": "Apache 2.0",
      "source": {
        "folder": "distilgpt2_conda/main",
        "files": [
          "__init__.py",
          "conda.yml",
          "model.py"
        ]
      },
      "deploy": {
        "pods": "1",
        "instance": "small",
        "timeout": 50000
      },
      "tags": [
        "Generative AI",
        "LLM"
      ]
    },
    "finetuned_flan_t5": {
      "name": "Finetuned FLAN-T5",
      "description": "Finetuning FLAN-T5 on financial QA data",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/google.svg",
      "license": "Apache 2.0",
      "source": {
        "folder": "flan_t5_finetuned_poetry/main",
        "files": [
          "__init__.py",
          "pyproject.toml",
          "model.py",
          "training.py",
          "dataset_loader.py",
          "helpers.py"
        ]
      },
      "build": {
        "instance": "medium"
      },
      "deploy": {
        "workers": "1",
        "pods": "1",
        "instance": "medium",
        "timeout": 50000
      },
      "tags": [
        "LLM",
        "Generative AI"
      ]
    },
    "flan_t5": {
      "name": "FLAN-T5",
      "description": "An enhanced T5 model trained on a mixture of tasks",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/google.svg",
      "featured": true,
      "license": "Apache 2.0",
      "source": {
        "folder": "flan_t5_poetry/main",
        "files": [
          "__init__.py",
          "pyproject.toml",
          "model.py"
        ]
      },
      "deploy": {
        "pods": "1",
        "instance": "small",
        "timeout": 50000
      },
      "tags": [
        "LLM"
      ]
    },
    "embeddings": {
      "name": "Sentence Embeddings",
      "description": "The all-MiniLM-L12-v2 model for semantic search",
      "license": "Apache 2.0",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/huggingface.png",
      "featured": true,
      "source": {
        "folder": "sentence_transformers_poetry/main",
        "files": [
          "__init__.py",
          "pyproject.toml",
          "model.py"
        ]
      },
      "deploy": {
        "pods": "1",
        "instance": "small"
      },
      "tags": [
        "Embeddings",
        "Semantic Search"
      ]
    },
    "llama2": {
      "name": "Llama-2",
      "description": "A leading open-source LLM",
      "license": "Llama 2",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/huggingface.png",
      "source": {
        "folder": "llama2/main",
        "files": [
          "__init__.py",
          "requirements.txt",
          "model.py"
        ]
      },
      "disabled": true,
      "build": {
        "instance": "small",
        "gpu_compatible": true
      },
      "deploy": {
        "pods": "1",
        "workers": "1",
        "instance": "gpu.a10.2xl",
        "timeout": 50000
      },
      "tags": [
        "LLM",
        "Generative AI"
      ]
    },
    "codegen": {
      "name": "CodeGen",
      "description": "Autoregressive language models for program synthesis and code generation",
      "license": "Apache-2.0",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/codegen.svg",
      "source": {
        "folder": "codegen_conda/main",
        "files": [
          "__init__.py",
          "conda.yml",
          "model.py"
        ]
      },
      "deploy": {
        "pods": "1",
        "instance": "small",
        "timeout": 50000
      },
      "tags": [
        "Generative AI",
        "LLM"
      ]
    },
    "gpt_neo": {
      "name": "GPT-Neo",
      "description": "An open-source variant of the GPT language model series",
      "image": "https://qwak-public.s3.amazonaws.com/qwak-frontend/onboarding/huggingface.png",
      "license": "Apache 2.0",
      "source": {
        "folder": "gpt_neo_conda/main",
        "files": [
          "__init__.py",
          "conda.yml",
          "model.py"
        ]
      },
      "build": {
        "instance": "medium"
      },
      "deploy": {
        "pods": "1",
        "instance": "medium",
        "timeout": 50000
      },
      "tags": [
        "Generative AI",
        "LLM"
      ]
    }
  }
}
