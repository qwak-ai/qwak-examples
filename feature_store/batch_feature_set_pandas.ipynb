{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09416862-25e8-470f-bf85-01d287143bfb",
   "metadata": {},
   "source": [
    "# JFrogML Feature Store Example - Batch Feature Set with Pandas Transformation\n",
    "\n",
    "Welcome to the JFrogML Feature Store example! In this tutorial, we'll guide you through creating a sample Data Source, transforming it into a Feature Set, and leveraging its features for model training and inference using the JFrogML Platform. \n",
    "\n",
    "Guides like this one aim to provide you with a starting point by offering a straightforward framework for working with JFrogML. However, we encourage you to explore our [comprehensive documentation](https://docs.qwak.com/docs/feature-store-overview) for more detailed and specific information.\n",
    "\n",
    "Before diving in, make sure you have the JFrogML SDK installed and authenticated. If you haven't done so already, follow these steps:\n",
    "\n",
    "1. [Install the JFrogML SDK](https://docs.qwak.com/docs/transformations#pyspark) - Ensure you have the SDK installed on your local environment.\n",
    "2. [Authenticate](https://docs.qwak.com/docs/installing-the-qwak-sdk#1-via-qwak-cli) - Authenticate with a new Personal or Service Qwak API Key.\n",
    "\n",
    "To gain a deeper understanding of Feature Stores and their importance in machine learning workflows, we recommend checking out our comprehensive [documentation](https://docs.qwak.com/docs/feature-store-overview) and our blog article on [What is a Feature Store](https://www.qwak.com/post/what-is-a-feature-store-in-ml). Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd037e5-c8b4-4c8d-9bdd-ce426dc22b09",
   "metadata": {},
   "source": [
    "## Create the S3-based Data Source\n",
    "\n",
    "In JFrogML, a Data Source serves as a configuration object that specifies how to access and fetch your data. It includes metadata such as name and description, connection details to the data store/storage, the query or resource to retrieve, and the relevant time column for indexing time series features.\n",
    "\n",
    "### Components of a Data Source:\n",
    "\n",
    "1. **Metadata**: Includes information like name, description, etc.\n",
    "2. **URL and Connection Details**: Specifies the connection details to the data store/storage.\n",
    "3. **Query or Resource**: Defines the resource (file, table, view) to retrieve data from.\n",
    "4. **Time Column**: Specifies the relevant time column for indexing time series features.\n",
    "\n",
    "In the following example, we'll connect to a publicly accessible S3 bucket and fetch data from a single CSV file, for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9c12dd-f46e-49e2-be07-931da11cf465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_source.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_source.py\n",
    "\n",
    "from qwak.feature_store.data_sources import CsvSource\n",
    "import pandas as pd\n",
    "\n",
    "# The S3 anonymous config class is required for public S3 buckets\n",
    "from qwak.feature_store.data_sources import AnonymousS3Configuration\n",
    "\n",
    "# Create a CsvSource object to represent a CSV data source \n",
    "# This example uses a CSV file from a public S3 bucket\n",
    "csv_source = CsvSource(\n",
    "    name='credit_risk_data',                                    # Name of the data source\n",
    "    description='A dataset of personal credit details',         # Description of the data source\n",
    "    date_created_column='date_created',                         # Column name that represents the creation date\n",
    "    path='s3://qwak-public/example_data/data_credit_risk.csv',  # S3 path to the CSV file \n",
    "    filesystem_configuration=AnonymousS3Configuration(),        # Configuration for anonymous access to S3\n",
    "    quote_character='\"',                                        # Character used for quoting in the CSV file\n",
    "    escape_character='\"'                                        # Character used for escaping in the CSV file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2484ec-e719-46d1-9d20-ef72e6f20747",
   "metadata": {},
   "source": [
    "### Additional Considerations for Registering Data Sources\n",
    "\n",
    "When registering Data Sources in JFrogML, it's essential to ensure that the underlying data store is accessible by the platform. Depending on your deployment model (Hybrid or SaaS), there are different ways to grant JFrogML access to your data.\n",
    "\n",
    "#### Accessing AWS Resources:\n",
    "\n",
    "If your data is stored in AWS services, you can grant access to JFrogML using an IAM role ARN. For detailed instructions, refer to our documentation on [Accessing AWS Resources with IAM Role](https://docs.qwak.com/docs/accessing-aws-resources-with-iam-role).\n",
    "\n",
    "#### Using JFrogML Secrets:\n",
    "\n",
    "Alternatively, you can pass the credentials as JFrogML Secrets. This approach provides a secure way to manage and authenticate access to your data. For more information, see [JFrogML Secret Management](https://docs.qwak.com/docs/secret-management).\n",
    "\n",
    "For more information about the types of Data Sources supported by JFrogML, refer to our documentation:\n",
    "- [Batch Data Sources](https://docs.qwak.com/docs/batch-data-sources)\n",
    "- [Streaming Data Sources](https://docs.qwak.com/docs/streaming-data-sources)\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sampling Data from the Data Source\n",
    "\n",
    "It's important to note that the data source cannot be used as a query engine independently (for now). Instead, it serves as a sampling mechanism to verify that the data is being queried properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fcc6d5-50db-401f-a41e-4c1c8c8938ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Source Data Types:\n",
      "\n",
      "age                  int64\n",
      "sex                 object\n",
      "job                  int64\n",
      "housing             object\n",
      "saving_account      object\n",
      "checking_account    object\n",
      "credit_amount        int64\n",
      "duration             int64\n",
      "purpose             object\n",
      "risk                object\n",
      "user_id             object\n",
      "date_created         int64\n",
      "dtype: object\n",
      "\n",
      "Data Source Sample :\n",
      "\n",
      "   age     sex  job housing saving_account checking_account  credit_amount  duration              purpose  risk                               user_id   date_created\n",
      "0   67    male    2     own           None           little           1169         6             radio/TV  good  baf1aed9-b16a-46f1-803b-e2b08c8b47de  1609459200000\n",
      "1   22  female    2     own         little         moderate           5951        48             radio/TV   bad  574a2cb7-f3ae-48e7-bd32-b44015bf9dd4  1609459200000\n",
      "2   49    male    1     own         little             None           2096        12            education  good  1b044db3-3bd1-4b71-a4e9-336210d6503f  1609459200000\n",
      "3   45    male    2    free         little           little           7882        42  furniture/equipment  good  ac8ec869-1a05-4df9-9805-7866ca42b31c  1609459200000\n",
      "4   53    male    2    free         little           little           4870        24                  car   bad  aa974eeb-ed0e-450b-90d0-4fe4592081c1  1609459200000\n",
      "5   35    male    1    free           None             None           9055        36            education  good  7b3d019c-82a7-42d9-beb8-2c57a246ff16  1609459200000\n",
      "6   53    male    2     own     quite rich             None           2835        24  furniture/equipment  good  6bc1fd70-897e-49f4-ae25-960d490cb74e  1609459200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run data_source.py\n",
    "\n",
    "df_sample = csv_source.get_sample()\n",
    "print (f\"Data Source Data Types:\\n\\n{df_sample.dtypes}\\n\")\n",
    "print (f\"Data Source Sample :\\n\\n{df_sample.head(7).to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d27c1-25fa-45d5-836c-d22aa3e35fab",
   "metadata": {},
   "source": [
    "## Registering the Data Source with the JFrogML Platform\n",
    "\n",
    "After verifying that the Data Source returns the desired results, the next step is to register it with the JFrogML Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4027c415-473c-4d62-a384-957d1f6dd7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that BatchInferenceClient and FeedbackClient are not available in the skinny package. In order to use them, please install them as extras: pip install \"qwak-inference[batch,feedback]\".\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Entities to register (0:00:00.01)\n",
      "ðŸ‘€ Found 0 Entities\n",
      "----------------------------------------\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Data Sources to register (0:00:00.00)\n",
      "ðŸ‘€ Found 1 Data Sources\n",
      "Validating 'credit_risk_data' data source\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m  (0:00:04.52)\n",
      "âœ… Validation completed successfully, got data source columns:\n",
      "column name       type\n",
      "----------------  ---------\n",
      "age               int\n",
      "sex               string\n",
      "job               int\n",
      "housing           string\n",
      "saving_account    string\n",
      "checking_account  string\n",
      "credit_amount     int\n",
      "duration          int\n",
      "purpose           string\n",
      "risk              string\n",
      "user_id           string\n",
      "date_created      timestamp\n",
      "Update existing Data Source 'credit_risk_data' from source file '/Users/haha/Projects/qwak-examples/feature_store/data_source.py'?\n",
      "continue? [y/N]: ----------------------------------------\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Feature Sets to register (0:00:00.00)\n",
      "ðŸ‘€ Found 0 Feature Set(s)\n"
     ]
    }
   ],
   "source": [
    "!echo \"Y\" | qwak features register -p data_source.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fabf0-06a1-4429-9129-1a14d83c9fc8",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "## Creating the Batch Feature Set from the Data Source\n",
    "\n",
    "When creating a Feature Set, it typically consists of the following components:\n",
    "\n",
    "- **Metadata:** Includes name, key, data sources, and the timestamp column used for indexing.\n",
    "- **Scheduling Expression:** For Batch Feature Sets, this defines when ingestion jobs should run.\n",
    "- **Cluster Type:** Specifies the resources to use for running the ingestion job.\n",
    "- **Backfill:** Determines how far back in time the Feature Set should ingest data.\n",
    "- **Transformation:** Can be SQL-based, based on PySpark DataFrames or UDF based via Spark Pandas for data transformation.\n",
    "\n",
    "[Read Policies](https://docs.qwak.com/docs/read-policies) instruct JFrogML on which data to fetch from the Data Source. \n",
    "- **NewOnly:** Fetches records created after the last ingestion.\n",
    "- **TimeFrame:** Fetches records within a specified timeframe.\n",
    "- **FullRead:** Fetches all data from the Data Source in every ingestion job, which can be heavy for main tables but useful for foreign key-based tables.\n",
    "\n",
    "For this example, we'll use FullRead since our sample Data Source is static, consisting of a single CSV file.\n",
    "\n",
    "The execution specification refers to the size of the cluster used for data ingestion. More information can be found in the [JFrogML docs](https://docs.qwak.com/docs/instance-sizes#feature-store).\n",
    "\n",
    "### The Pandas API on Spark transformation process\n",
    "\n",
    "A `pyspark.pandas.DataFrame` is analogous to a pandas DataFrame but leverages the distributed computation of a Spark cluster. Once your data resides in a Pandas on Spark DataFrame, it's advisable to carry out transformations directly within this DataFrame rather than switching to other data types like standard pandas. This is because converting to a standard pandas DataFrame consolidates the distributed data onto a single node, leading to sequential computation and performance degradation.\n",
    "\n",
    "The Qwak `transform` method should return a `PandasOnSparkTransformation` object, indicating your end-to-end transformation function, in this case, `extract_features`. You're not restricted to a single function; you can divide the logic into as many as necessary and call them within a main function passed to the transformation.\n",
    "\n",
    "The function's input will be a Python dictionary with data source names as keys and their associated values as Pandas on Spark DataFrames containing the ingested data from the DataSource.\n",
    "\n",
    "It's important to note that while this code is callable locally, via `get_sample()` as demonstrated in the next cell, it's not available for debugging, as the actual transformations will be executed remotely.\n",
    "\n",
    "To utilize Pandas API on Spark effectively, **ensure you have Python 3.8 installed** and `cloudpickle` locked to version `2.2.1`, as your code will be pickled and provided to JFrogML for registration and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49ac7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batch_feature_set_pandas.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile batch_feature_set_pandas.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import qwak.feature_store.feature_sets.batch as batch\n",
    "from qwak.feature_store.feature_sets.execution_spec import ClusterTemplate\n",
    "from qwak.feature_store.feature_sets.read_policies import ReadPolicy\n",
    "from qwak.feature_store.feature_sets.transformations import PandasOnSparkTransformation\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "\n",
    "# Global function definitions\n",
    "# These functions are defined globally and can be reused across multiple transformations.\n",
    "# They will be available to any part of the code that imports or references them.\n",
    "# This is useful when you want to define utility functions that can be shared across multiple feature sets or logic.\n",
    "\n",
    "def preprocess_date(df: ps.DataFrame) -> ps.DataFrame:\n",
    "    df['year'] = df['date_created'].dt.year\n",
    "    df['month'] = df['date_created'].dt.month\n",
    "\n",
    "    return df\n",
    "\n",
    "def encode_categorical_variables(df: ps.DataFrame) -> ps.DataFrame:\n",
    "    categorical_columns = ['sex', 'housing', 'saving_account', 'checking_account', 'purpose', 'risk']\n",
    "    for col in categorical_columns:\n",
    "        df[f'{col}_encoded'] = df[col].astype('category').cat.codes\n",
    "    df = df.drop(columns=categorical_columns)\n",
    "    return df\n",
    "\n",
    "@batch.feature_set(  \n",
    "    name=\"credit-risk-fs-pandas\",  # must contain dashes -, NOT underscores _\n",
    "    key=\"user_id\",  \n",
    "    data_sources={\"credit_risk_data\": ReadPolicy.FullRead},  \n",
    "    timestamp_column_name=\"date_created\"  \n",
    ")  \n",
    "@batch.scheduling(cron_expression=\"0 0 * * *\")  \n",
    "@batch.execution_specification(cluster_template=ClusterTemplate.MEDIUM)\n",
    "def transform():\n",
    "\n",
    "    # Functions defined within the `transform` method\n",
    "    # These are local to the 'transform' function and only available within its scope.\n",
    "\n",
    "    def calculate_credit_duration_ratio(df: ps.DataFrame) -> ps.DataFrame:\n",
    "        df['credit_duration_ratio'] = df['credit_amount'] / df['duration']\n",
    "        return df\n",
    "\n",
    "    def aggregate_user_data(df: ps.DataFrame) -> ps.DataFrame:\n",
    "        agg_df = df.groupby('user_id').agg({\n",
    "            'credit_amount': ['mean', 'sum'],\n",
    "            'duration': ['mean', 'sum'],\n",
    "            'age': 'first',\n",
    "            'job': 'first',\n",
    "            'risk_encoded': 'mean'\n",
    "        })\n",
    "        agg_df.columns = ['_'.join(col).strip() for col in agg_df.columns.values]\n",
    "        return agg_df.reset_index()\n",
    "\n",
    "    def merge_aggregated_data(df: ps.DataFrame, agg_df: ps.DataFrame) -> ps.DataFrame:\n",
    "        result_df = df.merge(agg_df, on='user_id', how='left', suffixes=('', '_agg'))\n",
    "        result_df['credit_amount_diff_from_avg'] = result_df['credit_amount'] - result_df['credit_amount_mean']\n",
    "        result_df['duration_diff_from_avg'] = result_df['duration'] - result_df['duration_mean']\n",
    "        return result_df\n",
    "\n",
    "    def extract_features(df_dict: Dict[str, ps.DataFrame], qwargs: Dict[str, Any]) -> ps.DataFrame:\n",
    "        # Extract the Pandas on Spark DataFrame containing credit risk data\n",
    "        risk_data = df_dict['credit_risk_data']\n",
    "\n",
    "        risk_data = preprocess_date(risk_data)\n",
    "        risk_data = encode_categorical_variables(risk_data)\n",
    "        risk_data = calculate_credit_duration_ratio(risk_data)\n",
    "\n",
    "        agg_df = aggregate_user_data(risk_data)\n",
    "        result_df = merge_aggregated_data(risk_data, agg_df)\n",
    "\n",
    "        return result_df\n",
    "    \n",
    "    return PandasOnSparkTransformation(function=extract_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea960ab-ffb2-4dd9-997d-494829ff625f",
   "metadata": {},
   "source": [
    "## Sampling the Data Source and Printing Data and Data Types\n",
    "\n",
    "If your data source takes more than 5 minutes to query or fetch a sample of the data (for example, due to long-running queries), your sampling process may fail with a timeout error. In such cases, you can skip validation during registration with Qwak and proceed to register your feature set, allowing it to run an ingestion job.\n",
    "\n",
    "### Note:\n",
    "The sampling process is essential for verifying that the data is queried properly. However, if it takes too long, you can proceed with the registration without validation and rely on the ingestion job to ensure data correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c75631eb-b157-47e3-9a5e-c65960acfd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Source Data Types:\n",
      "\n",
      "age                              int64\n",
      "job                              int64\n",
      "credit_amount                    int64\n",
      "duration                         int64\n",
      "user_id                         object\n",
      "date_created                     int64\n",
      "year                             int64\n",
      "month                            int64\n",
      "sex_encoded                      int64\n",
      "housing_encoded                  int64\n",
      "saving_account_encoded           int64\n",
      "checking_account_encoded         int64\n",
      "purpose_encoded                  int64\n",
      "risk_encoded                     int64\n",
      "credit_duration_ratio          float64\n",
      "credit_amount_mean             float64\n",
      "credit_amount_sum                int64\n",
      "duration_mean                  float64\n",
      "duration_sum                     int64\n",
      "age_first                        int64\n",
      "job_first                        int64\n",
      "risk_encoded_mean              float64\n",
      "credit_amount_diff_from_avg    float64\n",
      "duration_diff_from_avg         float64\n",
      "dtype: object\n",
      "\n",
      "Data Source Sample :\n",
      "\n",
      "   age  job  credit_amount  duration                               user_id   date_created  year  month  sex_encoded  housing_encoded  saving_account_encoded  checking_account_encoded  purpose_encoded  risk_encoded  credit_duration_ratio  credit_amount_mean  credit_amount_sum  duration_mean  duration_sum  age_first  job_first  risk_encoded_mean  credit_amount_diff_from_avg  duration_diff_from_avg\n",
      "0   67    2           1169         6  baf1aed9-b16a-46f1-803b-e2b08c8b47de  1609459200000  2021      1            1                1                      -1                         0                5             1             194.833333              1169.0               1169            6.0             6         67          2                1.0                          0.0                     0.0\n",
      "1   22    2           5951        48  574a2cb7-f3ae-48e7-bd32-b44015bf9dd4  1609459200000  2021      1            0                1                       0                         1                5             0             123.979167              5951.0               5951           48.0            48         22          2                0.0                          0.0                     0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run batch_feature_set_pandas.py\n",
    "\n",
    "df_sample = transform.get_sample()\n",
    "print (f\"Data Source Data Types:\\n\\n{df_sample.dtypes}\\n\")\n",
    "print (f\"Data Source Sample :\\n\\n{df_sample.head(2).to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5f593-7e74-466e-8e9a-22cd614ba101",
   "metadata": {},
   "source": [
    "## Visualizing Data in the Feature Store\n",
    "\n",
    "The displayed data represents the features stored in the feature store, which will be utilized in our JFrogML model for both training and inference purposes.\n",
    "\n",
    "Once we have confirmed that the data appears as expected and meets our requirements, we can proceed with registering the feature set in JFrogML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7d7713c-bf02-4d33-bd85-4af4ba6d3544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Entities to register (0:00:00.23)\n",
      "ðŸ‘€ Found 0 Entities\n",
      "----------------------------------------\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Data Sources to register (0:00:00.00)\n",
      "ðŸ‘€ Found 0 Data Sources\n",
      "----------------------------------------\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m Finding Feature Sets to register (0:00:00.00)\n",
      "ðŸ‘€ Found 1 Feature Set(s)\n",
      "Create new feature set 'credit-risk-fs-pandas' from source file '/Users/haha/Projects/qwak-examples/feature_store/batch_feature_set_pandas.py'?\n",
      "continue? [y/N]: Validating 'credit-risk-fs-pandas' feature set\n",
      "\u001b[K\u001b[?25h\u001b[34mâœ…\u001b[0m  (0:00:05.19)\n",
      "âœ… Validation completed successfully, got data source columns:\n",
      "column name                  type\n",
      "---------------------------  ---------\n",
      "age                          int\n",
      "job                          int\n",
      "credit_amount                int\n",
      "duration                     int\n",
      "user_id                      string\n",
      "date_created                 timestamp\n",
      "year                         bigint\n",
      "month                        bigint\n",
      "sex_encoded                  int\n",
      "housing_encoded              int\n",
      "saving_account_encoded       int\n",
      "checking_account_encoded     int\n",
      "purpose_encoded              int\n",
      "risk_encoded                 int\n",
      "credit_duration_ratio        double\n",
      "credit_amount_mean           double\n",
      "credit_amount_sum            bigint\n",
      "duration_mean                double\n",
      "duration_sum                 bigint\n",
      "age_first                    int\n",
      "job_first                    int\n",
      "risk_encoded_mean            double\n",
      "credit_amount_diff_from_avg  double\n",
      "duration_diff_from_avg       double\n"
     ]
    }
   ],
   "source": [
    "!echo \"Y\" | qwak features register -p batch_feature_set_pandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239e7f1-dd0d-40b7-9250-be2596f80438",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Verifying Feature Set Registration\n",
    "\n",
    "To ensure that the Feature Set has been successfully registered and is valid, execute the following command to list all Feature Sets associated with your JFrogML account:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d490ed-03c5-45d7-82c8-9a3d2bf80d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!qwak features list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd0aa9-3524-4abc-aecd-5b05f6f54886",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "For more information on the available Feature Store SDK commands, please use the CLI help:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d091acf-289a-4c72-abc1-5f7d88e09e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that BatchInferenceClient and FeedbackClient are not available in the skinny package. In order to use them, please install them as extras: pip install \"qwak-inference[batch,feedback]\".\n",
      "Usage: qwak features [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Commands for interacting with the Qwak Feature Store\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  backfill          Trigger a backfill process for a Feature Set\n",
      "  delete            Delete by name a feature store object - a feature...\n",
      "  execution-status  Retrieve the current status of an execution...\n",
      "  list              List registered feature sets\n",
      "  pause             Pause a running feature set\n",
      "  register          Register and deploy all feature store object under...\n",
      "  resume            Resume a paused feature set\n",
      "  trigger           Trigger a batch feature set job ingestion job\n"
     ]
    }
   ],
   "source": [
    "!qwak features --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe40f5-2638-4386-9772-cb2589c73bad",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "## Consuming Features from the Offline Feature Store (Training/Batch Inference)\n",
    "\n",
    "To retrieve features from the Offline Feature Store for training or batch inference, you can use two methods:\n",
    "\n",
    "1. **By List of IDs and Timestamp**:\n",
    "   - Fetches records associated with the provided set of keys, inserted at a specific timestamp.\n",
    "   - Query date must fall between the start and end timestamp.\n",
    "\n",
    "2. **By Date Range**:\n",
    "   - Retrieves all records within the specified date range.\n",
    "   - May include multiple records per key for time series data.\n",
    "\n",
    "\n",
    "For simplicity we will focus on the second option, but you can find more information on the first one in [our docs](https://docs.qwak.com/docs/getting-features-for-training#get-feature-values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "484e6d82-bfdd-4256-bc7d-23580713f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training data sample:\n",
      "\n",
      "                                user_id                    date_created  credit-risk-fs-pandas.age  credit-risk-fs-pandas.job  credit-risk-fs-pandas.credit_amount  credit-risk-fs-pandas.duration  credit-risk-fs-pandas.year  credit-risk-fs-pandas.month  credit-risk-fs-pandas.sex_encoded  credit-risk-fs-pandas.housing_encoded  credit-risk-fs-pandas.saving_account_encoded  credit-risk-fs-pandas.checking_account_encoded  credit-risk-fs-pandas.purpose_encoded  credit-risk-fs-pandas.risk_encoded  credit-risk-fs-pandas.credit_duration_ratio  credit-risk-fs-pandas.credit_amount_mean  credit-risk-fs-pandas.credit_amount_sum  credit-risk-fs-pandas.duration_mean  credit-risk-fs-pandas.duration_sum  credit-risk-fs-pandas.age_first  credit-risk-fs-pandas.job_first  credit-risk-fs-pandas.risk_encoded_mean  credit-risk-fs-pandas.credit_amount_diff_from_avg  credit-risk-fs-pandas.duration_diff_from_avg\n",
      "0  45b7836f-bf7c-4039-bc9e-d33982cc1fc5  2021-01-01 00:00:00.000000 UTC                         27                          2                                 4576                              45                        2021                            1                                  1                                      1                                             1                                               1                                      1                                   1                                   101.688889                                    4576.0                                     9152                                 45.0                                  90                               27                                2                                      1.0                                                0.0                                           0.0\n",
      "1  3c614f8e-daa6-41d5-be37-90f97042dc18  2021-01-01 00:00:00.000000 UTC                         23                          2                                 1275                              10                        2021                            1                                  0                                      1                                             0                                               2                                      4                                   1                                   127.500000                                    1275.0                                     1275                                 10.0                                  10                               23                                2                                      1.0                                                0.0                                           0.0\n",
      "2  545a7fe1-46e5-4c88-8e47-9796600308bb  2021-01-01 00:00:00.000000 UTC                         27                          1                                 2708                              15                        2021                            1                                  1                                      1                                             0                                              -1                                      4                                   1                                   180.533333                                    2708.0                                     2708                                 15.0                                  15                               27                                1                                      1.0                                                0.0                                           0.0\n",
      "3  896e92e2-7deb-4846-b691-8f52bdcadb2b  2021-01-01 00:00:00.000000 UTC                         61                          2                                 2012                              12                        2021                            1                                  0                                      1                                            -1                                              -1                                      3                                   1                                   167.666667                                    2012.0                                     2012                                 12.0                                  12                               61                                2                                      1.0                                                0.0                                           0.0\n",
      "4  9ec4049f-d4f3-44f0-99b2-04c382256e97  2021-01-01 00:00:00.000000 UTC                         31                          2                                  929                              24                        2021                            1                                  1                                      1                                            -1                                              -1                                      4                                   1                                    38.708333                                     929.0                                      929                                 24.0                                  24                               31                                2                                      1.0                                                0.0                                           0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the Feature Store clients used to fetch results\n",
    "from qwak.feature_store.offline import OfflineClientV2\n",
    "from qwak.feature_store.offline.feature_set_features import FeatureSetFeatures\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_SET = 'credit-risk-fs-pandas'\n",
    "FEATURES_LIST = [ 'age', 'job', 'credit_amount', 'duration', 'year', 'month', 'sex_encoded', 'housing_encoded', 'saving_account_encoded',\n",
    "                'checking_account_encoded', 'purpose_encoded', 'risk_encoded', 'credit_duration_ratio', 'credit_amount_mean',\n",
    "                'credit_amount_sum', 'duration_mean', 'duration_sum', 'age_first', 'job_first', 'risk_encoded_mean', 'credit_amount_diff_from_avg',\n",
    "                'duration_diff_from_avg']\n",
    "\n",
    "def fetch_training_features(start_time: datetime, end_time: datetime) -> pd.DataFrame: \n",
    "\n",
    "    offline_feature_store = OfflineClientV2()\n",
    "    \n",
    "    features = FeatureSetFeatures(\n",
    "        feature_set_name= FEATURE_SET,\n",
    "        feature_names= FEATURES_LIST)\n",
    "    \n",
    "    # It's recommended to be surrounded in a try/catch\n",
    "    features: pd.DataFrame = offline_feature_store.get_feature_range_values(\n",
    "        features=features,\n",
    "        start_date=start_time,\n",
    "        end_date=end_time\n",
    "    )\n",
    "\n",
    "    return features\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Define the date range for feature retrieval\n",
    "    feature_range_start = datetime(year=2023, month=1, day=1)\n",
    "    feature_range_end = datetime.today()\n",
    "\n",
    "    train_df = fetch_training_features(feature_range_start, feature_range_end)\n",
    "\n",
    "    print(f\"\\n\\nTraining data sample:\\n\\n{train_df.head().to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76ff96-59bf-4f5c-89d2-4450891cbeb5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Please note that although the Feature Set has been registered, it usually takes a couple of minutes to run the first ingestion job. This means you might not have any data to fetch until the ingestion job runs at least once.\n",
    "\n",
    "To verify the status of the ingestion, please refer to the JFrogML Dashboard -> Feature Sets -> `credit-risk-fs-pandas` -> Executions.\n",
    "\n",
    "![Feature Store Dashboard](PNGs/ingestion-job-finished-pandas.png)\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c4ec0-68f9-4657-91bb-31096e686acb",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "## Consuming Features for Real-Time Inference from the Online Store\n",
    "\n",
    "In the previous example, we retrieved historical data from the Offline Store, which is storing all the historical data. Now, we'll use the Online Store, which is optimized for real-time use-cases and provides a low-latency feature retrieval mechanism. \n",
    "JFrogML provides two ways to query the Online store and look up the most recent feature vector for a given key:\n",
    "\n",
    "###  1. Enriching Inference Requests with Features from Online Store\n",
    "\n",
    "JFrogML natively integrates the Model runtime with the Feature Store, offering an easy way to leverage very low-latency feature retrieval. This is done without specifically running a query, just by sending the feature set key in the model request input. This will automatically extract the latest features for that `key`, in our case `user` during a model serving request.\n",
    "\n",
    "\n",
    "Note: Below is an example code for local use only. If you're using it for a live model, please remove the `run_local` import.\n",
    "\n",
    "**The ModelSchema definition is mandatory to enable feature extraction via the OnlineClient or qwak.api decorator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9228cbeb-db89-4410-b021-b7cc2d654e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwak.model.tools import run_local # utility tooling for local testing and debugging - REMOVE BEFORE BUILDING REMOTELY\n",
    "\n",
    "from qwak.model.base import QwakModel\n",
    "from qwak.model.adapters import DefaultOutputAdapter, DataFrameInputAdapter\n",
    "from qwak.model.schema import ModelSchema, InferenceOutput\n",
    "from qwak.model.schema_entities import FeatureStoreInput, RequestInput\n",
    "import pandas as pd\n",
    "import qwak\n",
    "\n",
    "class CreditRiskModel(QwakModel):\n",
    "   \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    def schema(self) -> ModelSchema:\n",
    "        model_schema = ModelSchema(\n",
    "            inputs= [FeatureStoreInput(name=f'{FEATURE_SET}.{feature}') for feature in FEATURES_LIST],\n",
    "            outputs=[InferenceOutput(name=\"credit_score\", type=float)]\n",
    "        )\n",
    "        return model_schema\n",
    "\n",
    "    @qwak.api(\n",
    "        feature_extraction=True,\n",
    "        input_adapter=DataFrameInputAdapter(),\n",
    "        output_adapter=DefaultOutputAdapter()\n",
    "    )\n",
    "    def predict(self, df: pd.DataFrame, extracted_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(f\"\\nInput dataframe df:\\n{df}\")\n",
    "        print(f\"\\nFeature Set extracted dataframe:\\n{extracted_df.to_string()}\")\n",
    "        return pd.DataFrame([['score', 0.5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cedb207-6892-4f65-a61f-05ad7904b52e",
   "metadata": {},
   "source": [
    "Calling the model locally to test `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b15b602-fb16-4a28-aad6-161266975a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: \n",
      "\n",
      " {\"user_id\":{\"0\":\"45b7836f-bf7c-4039-bc9e-d33982cc1fc5\"}}\n",
      "\n",
      "Input dataframe df:\n",
      "                                user_id\n",
      "0  45b7836f-bf7c-4039-bc9e-d33982cc1fc5\n",
      "\n",
      "Feature Set extracted dataframe:\n",
      "                                user_id  credit-risk-fs-pandas.age  credit-risk-fs-pandas.job  credit-risk-fs-pandas.credit_amount  credit-risk-fs-pandas.duration  credit-risk-fs-pandas.year  credit-risk-fs-pandas.month  credit-risk-fs-pandas.sex_encoded  credit-risk-fs-pandas.housing_encoded  credit-risk-fs-pandas.saving_account_encoded  credit-risk-fs-pandas.checking_account_encoded  credit-risk-fs-pandas.purpose_encoded  credit-risk-fs-pandas.risk_encoded  credit-risk-fs-pandas.credit_duration_ratio  credit-risk-fs-pandas.credit_amount_mean  credit-risk-fs-pandas.credit_amount_sum  credit-risk-fs-pandas.duration_mean  credit-risk-fs-pandas.duration_sum  credit-risk-fs-pandas.age_first  credit-risk-fs-pandas.job_first  credit-risk-fs-pandas.risk_encoded_mean  credit-risk-fs-pandas.credit_amount_diff_from_avg  credit-risk-fs-pandas.duration_diff_from_avg\n",
      "0  45b7836f-bf7c-4039-bc9e-d33982cc1fc5                         27                          2                                 4576                              45                        2023                            3                                  1                                      1                                             1                                               1                                      1                                   1                                   101.688889                                      4576                                     9152                                   45                                  90                               27                                2                                        1                                                  0                                             0\n",
      "\n",
      "Prediction:  [{\"0\":\"score\",\"1\":0.5}]\n"
     ]
    }
   ],
   "source": [
    "def test_model_locally():\n",
    "    # Create a new instance of the model\n",
    "    m = CreditRiskModel()\n",
    "\n",
    "    # Define the columns\n",
    "    columns = [\"user_id\"]\n",
    "\n",
    "    # Define the data\n",
    "    data = [[\"45b7836f-bf7c-4039-bc9e-d33982cc1fc5\"]]\n",
    "    \n",
    "    # Create the DataFrame and convert it to JSON\n",
    "    json_payload = pd.DataFrame(data=data, columns=columns).to_json()\n",
    "\n",
    "    print(\"Predicting for: \\n\\n\", json_payload)\n",
    "    \n",
    "\n",
    "    # Run local inference using the model and print the prediction\n",
    "    # The run_local function is part of the qwak library and allows for local testing of the model\n",
    "    prediction = run_local(m, json_payload)\n",
    "    print(\"\\nPrediction: \", prediction)\n",
    "\n",
    "test_model_locally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed62ec8-3f5f-4be5-976c-597ed647a2cf",
   "metadata": {},
   "source": [
    "<br>\n",
    "As you can see, the we only sent the `user` ID in the prediction request, and JFrogML automatically extracted the relevant (latest) features for that key from the Feature Set specified in the Model Schema. \n",
    "\n",
    "This approach is automatically logging the extraction latency to the model Analytics.\n",
    "\n",
    "<br>\n",
    "\n",
    "###  2. Features Lookup with the OnlineClient\n",
    "\n",
    "With the previous approach we managed to enable a JFrogML model object to fetch features automatically and that approach is great for most cases. However what happens if we want to have more control over the keys we want to look up for at runtime, like for example looking up multiple keys for a single prediction request input. \n",
    "\n",
    "That's what the `OnlineClient` is for, to enable you explicit queries, as we'll exemplify below:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90cf537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realtime features extracted:\n",
      "\n",
      "                                user_id  credit-risk-fs-pandas.age  credit-risk-fs-pandas.job  credit-risk-fs-pandas.credit_amount  credit-risk-fs-pandas.duration  credit-risk-fs-pandas.year  credit-risk-fs-pandas.month  credit-risk-fs-pandas.sex_encoded  credit-risk-fs-pandas.housing_encoded  credit-risk-fs-pandas.saving_account_encoded  credit-risk-fs-pandas.checking_account_encoded  credit-risk-fs-pandas.purpose_encoded  credit-risk-fs-pandas.risk_encoded  credit-risk-fs-pandas.credit_duration_ratio  credit-risk-fs-pandas.credit_amount_mean  credit-risk-fs-pandas.credit_amount_sum  credit-risk-fs-pandas.duration_mean  credit-risk-fs-pandas.duration_sum  credit-risk-fs-pandas.age_first  credit-risk-fs-pandas.job_first  credit-risk-fs-pandas.risk_encoded_mean  credit-risk-fs-pandas.credit_amount_diff_from_avg  credit-risk-fs-pandas.duration_diff_from_avg\n",
      "0  06cc255a-aa07-4ec9-ac69-b896ccf05322                         31                          2                                 1935                              24                        2021                            1                                  1                                      1                                             0                                               1                                      0                                   0                                    80.625000                                      1935                                     1935                                   24                                  24                               31                                2                                        0                                                  0                                             0\n",
      "1  46ad9e4b-1d0f-47b7-a73d-71cc66538b03                         23                          0                                14555                               6                        2021                            1                                  1                                      1                                            -1                                               1                                      1                                   0                                  2425.833333                                     14555                                    14555                                    6                                   6                               23                                0                                        0                                                  0                                             0\n",
      "2  95ec0c53-4e27-4490-b85f-1448de70fc26                         25                          1                                  685                              12                        2021                            1                                  1                                      1                                             0                                               1                                      1                                   0                                    57.083333                                       685                                      685                                   12                                  12                               25                                1                                        0                                                  0                                             0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from qwak.feature_store.online.client import OnlineClient\n",
    "from qwak.model.schema_entities import FeatureStoreInput\n",
    "from qwak.model.schema import ModelSchema\n",
    "\n",
    "model_schema = ModelSchema(\n",
    "    inputs= [FeatureStoreInput(name=f'{FEATURE_SET}.{feature}') for feature in FEATURES_LIST],\n",
    "    outputs=[InferenceOutput(name=\"credit_score\", type=float)]\n",
    ")\n",
    "    \n",
    "online_client = OnlineClient()\n",
    "\n",
    "df = pd.DataFrame(columns=['user_id',],\n",
    "                  data   =[['06cc255a-aa07-4ec9-ac69-b896ccf05322'],\n",
    "                           ['46ad9e4b-1d0f-47b7-a73d-71cc66538b03'],\n",
    "                           ['95ec0c53-4e27-4490-b85f-1448de70fc26']])\n",
    "                  \n",
    "online_features = online_client.get_feature_values(model_schema, df)\n",
    "\n",
    "\n",
    "print(f\"\\nRealtime features extracted:\\n\\n{online_features.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4cae4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "You may have noticed that the FeatureStoreInput names contain both the feature set name and the feature name. This design allows you to specify and utilize multiple feature sets within the same request.\n",
    "\n",
    "Similar to the previous option, the `ModelSchema` is a required component. It informs JFrogML about the features to include in the lookup.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwak-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
